{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo8RnaiRug7e"
      },
      "source": [
        "## **Modelo CNN Simple - ResNet18 + Dropout + Soft Attention Espacial** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kTmTkZCHywa2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definición de transformación de los datos de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-4fhcf_yxMv"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),  # Recorte aleatorio con zoom entre 80%-100%\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Voltea horizontalmente con 50% de probabilidad\n",
        "    transforms.RandomRotation(15),  # Rotación aleatoria hasta 15 grados\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Ajuste aleatorio de color\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Pequeños desplazamientos aleatorios\n",
        "    transforms.Resize((128, 128)),  # Redimensionar después de las transformaciones\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalización de ImageNet\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Solo redimensionar en validación (sin data augmentation)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definición del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u-v6MsjVzY6k"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (str): Ruta al archivo CSV con las imágenes y sus etiquetas.\n",
        "            img_dir (str): Ruta al directorio que contiene las imágenes.\n",
        "            transform (callable, optional): Transformaciones que se aplican a las imágenes.\n",
        "        \"\"\"\n",
        "        self.img_labels = pd.read_csv(csv_file)  # Leer el archivo CSV con las etiquetas\n",
        "        self.img_dir = img_dir  # Ruta donde están las imágenes\n",
        "        self.transform = transform  # Transformaciones a aplicar\n",
        "\n",
        "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.img_labels['diagnosis'].unique())}\n",
        "    def __len__(self):\n",
        "        \"\"\"Retorna el número total de imágenes en el dataset\"\"\"\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Obtiene una imagen y su etiqueta\"\"\"\n",
        "        img_name = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])  # Nombre de la imagen\n",
        "        image = Image.open(img_name)  # Abrir la imagen\n",
        "        label = self.class_to_idx[self.img_labels.iloc[idx, 3]] # Etiqueta asociada\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)  # Aplicar transformaciones si es necesario\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rutas de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Leer el CSV\n",
        "csvRoute=\"./content/GPTeam-DeepLearning/Dataset/bcn_20k_train.csv\"\n",
        "imagesFolderRoute = \"./content/GPTeam-DeepLearning/Dataset/bcn_20k_train/\"\n",
        "trainDataJsonRoute = \"./content/GPTeam-DeepLearning/Dataset/data_train_resnet18_softAtt.json\"\n",
        "validationDataJsonRoute= \"./content/GPTeam-DeepLearning/Dataset/data_val_resnet18_softAtt.json\"\n",
        "filteredCsvRoute = \"./content/GPTeam-DeepLearning/Dataset/bcn_20k_train_filtrado.csv\"\n",
        "logsRoute = \"./runs\"\n",
        "savedParametersRoute = \"./saved_models_parameters/Parameters\"\n",
        "savedModelsRoute = \"./saved_models_parameters/Models\"\n",
        "savedResultsRoute = \"./results\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generación del dataset de entrenamiento y validación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Carga del dataframe***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bcn_filename</th>\n",
              "      <th>age_approx</th>\n",
              "      <th>anatom_site_general</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>capture_date</th>\n",
              "      <th>sex</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BCN_0000000001.jpg</td>\n",
              "      <td>55.0</td>\n",
              "      <td>anterior torso</td>\n",
              "      <td>MEL</td>\n",
              "      <td>BCN_0003884</td>\n",
              "      <td>2012-05-16</td>\n",
              "      <td>male</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BCN_0000000003.jpg</td>\n",
              "      <td>50.0</td>\n",
              "      <td>anterior torso</td>\n",
              "      <td>MEL</td>\n",
              "      <td>BCN_0000019</td>\n",
              "      <td>2015-07-09</td>\n",
              "      <td>female</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BCN_0000000004.jpg</td>\n",
              "      <td>85.0</td>\n",
              "      <td>head/neck</td>\n",
              "      <td>SCC</td>\n",
              "      <td>BCN_0003499</td>\n",
              "      <td>2015-11-23</td>\n",
              "      <td>male</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BCN_0000000006.jpg</td>\n",
              "      <td>60.0</td>\n",
              "      <td>anterior torso</td>\n",
              "      <td>NV</td>\n",
              "      <td>BCN_0003316</td>\n",
              "      <td>2015-06-16</td>\n",
              "      <td>male</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BCN_0000000010.jpg</td>\n",
              "      <td>30.0</td>\n",
              "      <td>anterior torso</td>\n",
              "      <td>BCC</td>\n",
              "      <td>BCN_0004874</td>\n",
              "      <td>2014-02-18</td>\n",
              "      <td>female</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         bcn_filename  age_approx anatom_site_general diagnosis    lesion_id  \\\n",
              "0  BCN_0000000001.jpg        55.0      anterior torso       MEL  BCN_0003884   \n",
              "1  BCN_0000000003.jpg        50.0      anterior torso       MEL  BCN_0000019   \n",
              "2  BCN_0000000004.jpg        85.0           head/neck       SCC  BCN_0003499   \n",
              "3  BCN_0000000006.jpg        60.0      anterior torso        NV  BCN_0003316   \n",
              "4  BCN_0000000010.jpg        30.0      anterior torso       BCC  BCN_0004874   \n",
              "\n",
              "  capture_date     sex  split  \n",
              "0   2012-05-16    male  train  \n",
              "1   2015-07-09  female  train  \n",
              "2   2015-11-23    male  train  \n",
              "3   2015-06-16    male  train  \n",
              "4   2014-02-18  female  train  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(csvRoute)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Exclusión de clases menos representativas***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Definir las clases que deseas excluir por su nombre\n",
        "clases_a_excluir = ['SCC', 'DF', 'VASC']  # Sustituye estos nombres por las clases que quieres excluir\n",
        "\n",
        "# Filtrar el DataFrame para excluir las clases especificadas\n",
        "df_filtrado = df[~df['diagnosis'].isin(clases_a_excluir)]\n",
        "\n",
        "df_filtrado.to_csv(filteredCsvRoute, index=False)\n",
        "\n",
        "df_filtrado['diagnosis'].unique()\n",
        "\n",
        "df_original = df.copy()\n",
        "\n",
        "df = df_filtrado.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Busqueda de spliteo adecuado (sin lesson_id iguales para dataset de entrenamiento y validación)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random state encontrado: 25\n"
          ]
        }
      ],
      "source": [
        "# Obtener los valores únicos de lesion_id\n",
        "unique_lesions = df['lesion_id'].unique()\n",
        "\n",
        "# Búsqueda del mejor split\n",
        "best_train, best_test = None, None\n",
        "target_ratio = 0.8 * len(df)\n",
        "\n",
        "for seed in range(1000):  # Exploramos diferentes random_state\n",
        "    train_ids, test_ids = train_test_split(unique_lesions, test_size=0.2, random_state=seed)\n",
        "\n",
        "    x_train = df[df['lesion_id'].isin(train_ids)]\n",
        "    x_test = df[df['lesion_id'].isin(test_ids)]\n",
        "\n",
        "    # Verificar que la cantidad de filas sea la correcta Y que los lesion_id no se repitan\n",
        "    if abs(len(x_train) - target_ratio) < 1 and set(x_train['lesion_id']).isdisjoint(set(x_test['lesion_id'])):\n",
        "        best_train, best_test = x_train, x_test\n",
        "        print(f\"Random state encontrado: {seed}\")\n",
        "        break\n",
        "\n",
        "# Si no se encontró un split válido, lanzar error\n",
        "if best_train is None or best_test is None:\n",
        "    raise ValueError(\"No se encontró un split válido después de 1000 intentos\")\n",
        "\n",
        "# Asignar los mejores valores encontrados\n",
        "train_df, val_df = best_train, best_test\n",
        "\n",
        "assert set(train_df['lesion_id']).isdisjoint(set(val_df['lesion_id'])), \"Error: Hay lesion_id repetidos entre train_df y val_df\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VERIFICACION ADICIONAL DE NO REPETICION DE LESSIONID EN AMBOS DATASETS\n",
        "for idtrain in train_df['lesion_id'].unique():\n",
        "    for idval in val_df['lesion_id'].unique():\n",
        "        if idtrain.strip() == idval.strip():\n",
        "            print(\"Coincidence found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Carga de las imágenes***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear el dataset de entrenamiento y validación\n",
        "train_dataset = CustomDataset(csv_file=filteredCsvRoute, img_dir=imagesFolderRoute, transform=train_transform)\n",
        "val_dataset = CustomDataset(csv_file=filteredCsvRoute, img_dir=imagesFolderRoute, transform=val_transform)\n",
        "\n",
        "# Actualizar los datasets con los subconjuntos correspondientes\n",
        "train_dataset.img_labels = train_df\n",
        "val_dataset.img_labels = val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de imagenes faltantes: 0\n"
          ]
        }
      ],
      "source": [
        "# Verificación de la carga de todos los arhivos\n",
        "archivos_en_directorio = []\n",
        "# Recorrer todos los archivos en el directorio\n",
        "for archivo in os.listdir(imagesFolderRoute):\n",
        "    if os.path.isfile(os.path.join(imagesFolderRoute, archivo)):\n",
        "        archivos_en_directorio.append(archivo)\n",
        "\n",
        "# La columna del DataFrame con los nombres de los archivos\n",
        "column_files = df['bcn_filename']\n",
        "# Convertir las listas a conjuntos para realizar la diferencia\n",
        "set_column_files = set(column_files)\n",
        "set_archivos_en_drive = set(archivos_en_directorio)\n",
        "valores_faltantes = set_column_files - set_archivos_en_drive\n",
        "\n",
        "print(f\"Cantidad de imagenes faltantes: {len(valores_faltantes)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Guardado de los datasets divididos inicialmente**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Guardado de data de dataframes de entrenamiento y validación**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.to_json(trainDataJsonRoute, orient='records', lines=True)\n",
        "val_df.to_json(validationDataJsonRoute, orient='records', lines=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Definición del Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mecanismo de Soft-Attention Espacial\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv_attention = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 1, kernel_size=1),  # Mapa de atención 1x1\n",
        "            nn.Softmax(dim=2)                           # Normalización espacial\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x: (batch, 512, H, W) [Ej: (batch, 512, 7, 7)]\n",
        "        # Generar mapa de atención (batch, 1, H, W)\n",
        "        attn_weights = self.conv_attention(x)\n",
        "        # Aplicar atención: características * pesos\n",
        "        attended_features = x * attn_weights  # Broadcasting automático\n",
        "        \n",
        "        return attended_features\n",
        "\n",
        "\n",
        "# Modelo ResNet18 con Dropout + Soft-Attention\n",
        "class ResNet18WithAttention(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet18WithAttention, self).__init__()\n",
        "        # 1. Cargar ResNet18 preentrenado\n",
        "        self.resnet18 = models.resnet18(pretrained=True)\n",
        "        \n",
        "        # 2. Congelar capas convolucionales\n",
        "        for param in self.resnet18.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # 2.1 Descongelar la ultima capa\n",
        "        for param in self.resnet18.layer4.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        # 2.1 Descongelar la ultima capa\n",
        "        for param in self.resnet18.layer3.parameters():\n",
        "            param.requires_grad = True\n",
        "        \n",
        "        # 3. Añadir mecanismo de atención espacial\n",
        "        self.attention = SpatialAttention(in_channels=512)  # ResNet18 tiene 512 canales al final\n",
        "        \n",
        "        # 4. Modificar capas FC con Dropout\n",
        "        self.resnet18.fc = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extraer características hasta la última capa convolucional\n",
        "        x = self.resnet18.conv1(x)\n",
        "        x = self.resnet18.bn1(x)\n",
        "        x = self.resnet18.relu(x)\n",
        "        x = self.resnet18.maxpool(x)\n",
        "        x = self.resnet18.layer1(x)\n",
        "        x = self.resnet18.layer2(x)\n",
        "        x = self.resnet18.layer3(x)\n",
        "        x = self.resnet18.layer4(x)  # Salida: (batch, 512, 7, 7)\n",
        "        \n",
        "        # Aplicar atención espacial\n",
        "        x = self.attention(x)  # (batch, 512, 7, 7) con pesos aprendidos\n",
        "        \n",
        "        # Global Average Pooling y clasificación\n",
        "        x = self.resnet18.avgpool(x)  # (batch, 512, 1, 1)\n",
        "        x = torch.flatten(x, 1)       # (batch, 512)\n",
        "        x = self.resnet18.fc(x)       # (batch, num_classes)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Viisualización de la ejecución del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ejecutar desde cmd lo siguiente para ver desde el navegador el menú de tensorboard: tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Entrenamiento y validación del modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Definición de gráficas adicionales a emplear**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función para registrar el heatmap (matriz de confusión)\n",
        "def log_heatmap(writer, epoch, ground_truth, predictions, labels):\n",
        "    # Calcula la matriz de confusión usando el orden de las etiquetas\n",
        "    cm = confusion_matrix(ground_truth, predictions, labels=range(len(labels)))\n",
        "    \n",
        "    # Crear la figura\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=labels, yticklabels=labels, ax=ax)\n",
        "    ax.set_xlabel(\"Predicción\")\n",
        "    ax.set_ylabel(\"Groundtruth\")\n",
        "    ax.set_title(\"Matriz de Confusión\")\n",
        "    \n",
        "    # Registrar la figura en TensorBoard\n",
        "    writer.add_figure(\"Heatmap\", fig, global_step=epoch)\n",
        "    plt.close(fig)\n",
        "\n",
        "# Función para registrar la grilla 2x2 de TP, FP, TN, FN (para clasificación binaria)\n",
        "def log_values_predicted(writer, epoch, ground_truth, predictions):\n",
        "    # Calcular la matriz de confusión\n",
        "    cm = confusion_matrix(ground_truth, predictions, labels=[0, 1])\n",
        "    \n",
        "    # Crear anotaciones combinando etiqueta y valor\n",
        "    annot = np.array([\n",
        "        [f\"TN\\n{cm[0,0]}\", f\"FP\\n{cm[0,1]}\"],\n",
        "        [f\"FN\\n{cm[1,0]}\", f\"TP\\n{cm[1,1]}\"]\n",
        "    ])\n",
        "    \n",
        "    # Crear el heatmap\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=annot, fmt=\"\", cmap=\"Blues\",\n",
        "                xticklabels=[\"False\", \"True\"],\n",
        "                yticklabels=[\"False\", \"True\"],\n",
        "                cbar=True, ax=ax)\n",
        "    ax.set_xlabel(\"Eje Predicho (False/True)\")\n",
        "    ax.set_ylabel(\"Eje Verdadero (False/True)\")\n",
        "    ax.set_title(\"Predicción de valores\")\n",
        "    \n",
        "    # Registrar la figura en TensorBoard\n",
        "    writer.add_figure(\"Predicción de valores\", fig, global_step=epoch)\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Seteo del dispositivo a usar**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dispositivo utilizado: cuda (NVIDIA GeForce GTX 1650 SUPER)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    print(F\"Dispositivo utilizado: {device} ({torch.cuda.get_device_name()})\")\n",
        "else:\n",
        "    print(F\"Dispositivo utilizado: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Especificación de parámetros**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate = 0.0001\n",
        "num_classes = 5\n",
        "num_epochs = 60\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ejecución del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 1/60 - Training: 100%|██████████| 294/294 [04:07<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60 FINISHED => Train Loss: 1.4022, Val Loss: 1.2332, Train Acc: 41.78%, Val Acc: 41.78%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/60 - Training: 100%|██████████| 294/294 [04:02<00:00,  1.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/60 FINISHED => Train Loss: 1.2365, Val Loss: 1.1406, Train Acc: 52.98%, Val Acc: 52.98%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/60 - Training: 100%|██████████| 294/294 [04:04<00:00,  1.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/60 FINISHED => Train Loss: 1.1633, Val Loss: 1.1004, Train Acc: 56.34%, Val Acc: 56.34%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/60 - Training: 100%|██████████| 294/294 [04:08<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/60 FINISHED => Train Loss: 1.1279, Val Loss: 1.0697, Train Acc: 56.94%, Val Acc: 56.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/60 - Training: 100%|██████████| 294/294 [04:07<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/60 FINISHED => Train Loss: 1.0854, Val Loss: 1.0490, Train Acc: 58.87%, Val Acc: 58.87%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/60 - Training: 100%|██████████| 294/294 [04:13<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/60 FINISHED => Train Loss: 1.0540, Val Loss: 1.0231, Train Acc: 60.10%, Val Acc: 60.10%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/60 - Training: 100%|██████████| 294/294 [04:36<00:00,  1.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/60 FINISHED => Train Loss: 1.0433, Val Loss: 1.0108, Train Acc: 61.25%, Val Acc: 61.25%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/60 - Training: 100%|██████████| 294/294 [04:07<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/60 FINISHED => Train Loss: 1.0204, Val Loss: 1.0091, Train Acc: 60.87%, Val Acc: 60.87%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/60 - Training: 100%|██████████| 294/294 [04:10<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/60 FINISHED => Train Loss: 1.0024, Val Loss: 1.0003, Train Acc: 62.42%, Val Acc: 62.42%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/60 FINISHED => Train Loss: 0.9910, Val Loss: 0.9775, Train Acc: 62.53%, Val Acc: 62.53%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/60 - Training: 100%|██████████| 294/294 [04:10<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/60 FINISHED => Train Loss: 0.9828, Val Loss: 0.9808, Train Acc: 62.55%, Val Acc: 62.55%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/60 FINISHED => Train Loss: 0.9675, Val Loss: 0.9745, Train Acc: 63.63%, Val Acc: 63.63%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/60 - Training: 100%|██████████| 294/294 [04:05<00:00,  1.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/60 FINISHED => Train Loss: 0.9673, Val Loss: 0.9697, Train Acc: 63.37%, Val Acc: 63.37%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/60 - Training: 100%|██████████| 294/294 [04:13<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/60 FINISHED => Train Loss: 0.9515, Val Loss: 0.9614, Train Acc: 63.65%, Val Acc: 63.65%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/60 - Training: 100%|██████████| 294/294 [04:10<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/60 FINISHED => Train Loss: 0.9473, Val Loss: 0.9588, Train Acc: 64.18%, Val Acc: 64.18%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/60 - Training: 100%|██████████| 294/294 [04:02<00:00,  1.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/60 FINISHED => Train Loss: 0.9305, Val Loss: 0.9607, Train Acc: 64.71%, Val Acc: 64.71%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/60 - Training: 100%|██████████| 294/294 [03:47<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/60 FINISHED => Train Loss: 0.9210, Val Loss: 0.9536, Train Acc: 64.91%, Val Acc: 64.91%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/60 - Training: 100%|██████████| 294/294 [03:47<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/60 FINISHED => Train Loss: 0.9211, Val Loss: 0.9495, Train Acc: 64.96%, Val Acc: 64.96%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/60 - Training: 100%|██████████| 294/294 [03:46<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/60 FINISHED => Train Loss: 0.9070, Val Loss: 0.9441, Train Acc: 65.52%, Val Acc: 65.52%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/60 - Training: 100%|██████████| 294/294 [03:46<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/60 FINISHED => Train Loss: 0.9111, Val Loss: 0.9464, Train Acc: 65.55%, Val Acc: 65.55%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/60 - Training: 100%|██████████| 294/294 [03:46<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/60 FINISHED => Train Loss: 0.8989, Val Loss: 0.9462, Train Acc: 66.10%, Val Acc: 66.10%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/60 - Training: 100%|██████████| 294/294 [04:04<00:00,  1.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/60 FINISHED => Train Loss: 0.8895, Val Loss: 0.9411, Train Acc: 66.33%, Val Acc: 66.33%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/60 - Training: 100%|██████████| 294/294 [04:08<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/60 FINISHED => Train Loss: 0.8954, Val Loss: 0.9364, Train Acc: 65.65%, Val Acc: 65.65%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/60 - Training: 100%|██████████| 294/294 [04:08<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/60 FINISHED => Train Loss: 0.8864, Val Loss: 0.9393, Train Acc: 66.72%, Val Acc: 66.72%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/60 - Training: 100%|██████████| 294/294 [04:02<00:00,  1.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/60 FINISHED => Train Loss: 0.8765, Val Loss: 0.9373, Train Acc: 66.50%, Val Acc: 66.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/60 - Training: 100%|██████████| 294/294 [04:03<00:00,  1.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/60 FINISHED => Train Loss: 0.8627, Val Loss: 0.9645, Train Acc: 67.06%, Val Acc: 67.06%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/60 - Training: 100%|██████████| 294/294 [04:03<00:00,  1.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/60 FINISHED => Train Loss: 0.8656, Val Loss: 0.9435, Train Acc: 67.18%, Val Acc: 67.18%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/60 - Training: 100%|██████████| 294/294 [04:10<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/60 FINISHED => Train Loss: 0.8522, Val Loss: 0.9474, Train Acc: 67.54%, Val Acc: 67.54%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/60 - Training: 100%|██████████| 294/294 [04:14<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/60 FINISHED => Train Loss: 0.8466, Val Loss: 0.9419, Train Acc: 67.87%, Val Acc: 67.87%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/60 - Training: 100%|██████████| 294/294 [04:12<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/60 FINISHED => Train Loss: 0.8475, Val Loss: 0.9343, Train Acc: 67.78%, Val Acc: 67.78%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/60 - Training: 100%|██████████| 294/294 [04:11<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31/60 FINISHED => Train Loss: 0.8454, Val Loss: 0.9437, Train Acc: 68.15%, Val Acc: 68.15%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/60 - Training: 100%|██████████| 294/294 [04:10<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32/60 FINISHED => Train Loss: 0.8470, Val Loss: 0.9422, Train Acc: 68.14%, Val Acc: 68.14%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/60 - Training: 100%|██████████| 294/294 [04:07<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33/60 FINISHED => Train Loss: 0.8382, Val Loss: 0.9362, Train Acc: 68.20%, Val Acc: 68.20%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34/60 FINISHED => Train Loss: 0.8211, Val Loss: 0.9338, Train Acc: 68.90%, Val Acc: 68.90%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35/60 FINISHED => Train Loss: 0.8285, Val Loss: 0.9303, Train Acc: 68.83%, Val Acc: 68.83%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/60 - Training: 100%|██████████| 294/294 [04:10<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36/60 FINISHED => Train Loss: 0.8289, Val Loss: 0.9403, Train Acc: 69.06%, Val Acc: 69.06%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/60 - Training: 100%|██████████| 294/294 [04:10<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37/60 FINISHED => Train Loss: 0.8216, Val Loss: 0.9295, Train Acc: 68.93%, Val Acc: 68.93%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/60 - Training: 100%|██████████| 294/294 [04:11<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38/60 FINISHED => Train Loss: 0.8243, Val Loss: 0.9363, Train Acc: 68.54%, Val Acc: 68.54%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/60 - Training: 100%|██████████| 294/294 [04:10<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39/60 FINISHED => Train Loss: 0.8234, Val Loss: 0.9308, Train Acc: 68.83%, Val Acc: 68.83%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40/60 FINISHED => Train Loss: 0.8164, Val Loss: 0.9375, Train Acc: 69.50%, Val Acc: 69.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/60 - Training: 100%|██████████| 294/294 [04:08<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41/60 FINISHED => Train Loss: 0.8262, Val Loss: 0.9323, Train Acc: 68.43%, Val Acc: 68.43%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/60 - Training: 100%|██████████| 294/294 [04:10<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42/60 FINISHED => Train Loss: 0.8121, Val Loss: 0.9427, Train Acc: 69.03%, Val Acc: 69.03%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43/60 FINISHED => Train Loss: 0.8128, Val Loss: 0.9378, Train Acc: 69.23%, Val Acc: 69.23%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44/60 FINISHED => Train Loss: 0.8063, Val Loss: 0.9445, Train Acc: 69.22%, Val Acc: 69.22%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45/60 FINISHED => Train Loss: 0.8074, Val Loss: 0.9268, Train Acc: 69.37%, Val Acc: 69.37%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/60 - Training: 100%|██████████| 294/294 [04:08<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46/60 FINISHED => Train Loss: 0.8021, Val Loss: 0.9330, Train Acc: 69.60%, Val Acc: 69.60%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/60 - Training: 100%|██████████| 294/294 [04:05<00:00,  1.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47/60 FINISHED => Train Loss: 0.8081, Val Loss: 0.9438, Train Acc: 69.38%, Val Acc: 69.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/60 - Training: 100%|██████████| 294/294 [04:05<00:00,  1.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48/60 FINISHED => Train Loss: 0.8052, Val Loss: 0.9377, Train Acc: 69.50%, Val Acc: 69.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49/60 - Training: 100%|██████████| 294/294 [04:05<00:00,  1.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49/60 FINISHED => Train Loss: 0.8095, Val Loss: 0.9367, Train Acc: 69.70%, Val Acc: 69.70%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50/60 - Training: 100%|██████████| 294/294 [04:05<00:00,  1.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50/60 FINISHED => Train Loss: 0.8043, Val Loss: 0.9317, Train Acc: 69.54%, Val Acc: 69.54%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 51/60 - Training: 100%|██████████| 294/294 [04:07<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51/60 FINISHED => Train Loss: 0.8072, Val Loss: 0.9311, Train Acc: 69.85%, Val Acc: 69.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 52/60 - Training: 100%|██████████| 294/294 [04:11<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52/60 FINISHED => Train Loss: 0.7970, Val Loss: 0.9433, Train Acc: 69.82%, Val Acc: 69.82%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 53/60 - Training: 100%|██████████| 294/294 [04:10<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53/60 FINISHED => Train Loss: 0.7984, Val Loss: 0.9334, Train Acc: 70.19%, Val Acc: 70.19%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 54/60 - Training: 100%|██████████| 294/294 [04:17<00:00,  1.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54/60 FINISHED => Train Loss: 0.7920, Val Loss: 0.9348, Train Acc: 69.69%, Val Acc: 69.69%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 55/60 - Training: 100%|██████████| 294/294 [04:11<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55/60 FINISHED => Train Loss: 0.7895, Val Loss: 0.9340, Train Acc: 70.50%, Val Acc: 70.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 56/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56/60 FINISHED => Train Loss: 0.7972, Val Loss: 0.9320, Train Acc: 69.77%, Val Acc: 69.77%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 57/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57/60 FINISHED => Train Loss: 0.7987, Val Loss: 0.9364, Train Acc: 69.85%, Val Acc: 69.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 58/60 - Training: 100%|██████████| 294/294 [04:12<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58/60 FINISHED => Train Loss: 0.7957, Val Loss: 0.9297, Train Acc: 70.41%, Val Acc: 70.41%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 59/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59/60 FINISHED => Train Loss: 0.7975, Val Loss: 0.9401, Train Acc: 69.76%, Val Acc: 69.76%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 60/60 - Training: 100%|██████████| 294/294 [04:09<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60/60 FINISHED => Train Loss: 0.7983, Val Loss: 0.9386, Train Acc: 70.11%, Val Acc: 70.11%\n"
          ]
        }
      ],
      "source": [
        "# Inicialización de tensorboard\n",
        "executionModelDateTime = datetime.now().strftime(\"Ejecucion %d-%m-%Y %H-%M\")\n",
        "writer = SummaryWriter(log_dir=os.path.join(logsRoute,executionModelDateTime))\n",
        "\n",
        "# Crear los DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "# Definición de la cantidad de clases, la función de perdida, el optimizador y el learning rate estático\n",
        "modelAt = ResNet18WithAttention(num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(modelAt.parameters(), lr=learning_rate, momentum=0.9,weight_decay=1e-3)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "model = modelAt.to(device)\n",
        "executionStatistics_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Modo entrenamiento\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "\n",
        "    # Entrenamiento\n",
        "    for inputs, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", leave=True):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Estadísticas de la pérdida\n",
        "        running_loss += loss.item()\n",
        "        # Precisión\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_preds += (predicted == labels).sum().item()\n",
        "        total_preds += labels.size(0)\n",
        "\n",
        "    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_dataloader)}, Accuracy: {100 * correct_preds / total_preds}%\")\n",
        "    train_loss = running_loss / len(train_dataloader)\n",
        "    train_accuracy = 100 * correct_preds / total_preds\n",
        "\n",
        "    # Validación\n",
        "    model.eval()  # Modo evaluación\n",
        "    running_val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    all_groundtruth = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():  # No calcular gradientes durante la validación\n",
        "        for inputs, labels in val_dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_val_loss += loss.item()\n",
        "            \n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_val += (predicted == labels).sum().item()  # Usamos correct_val en lugar de correct_preds\n",
        "            total_val += labels.size(0)  # Usamos total_val en lugar de total_preds\n",
        "\n",
        "            all_groundtruth.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    val_loss = running_val_loss/len(val_dataloader)\n",
        "    val_accuracy = 100 * correct_preds / total_preds\n",
        "    \n",
        "    # Ajustar la tasa de aprendizaje si la pérdida de validación no mejora\n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    # Agregar valores a TensorBoard\n",
        "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
        "    writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\n",
        "    writer.add_scalar(\"Accuracy/Train\", train_accuracy, epoch)\n",
        "    writer.add_scalar(\"Accuracy/Validation\", val_accuracy, epoch)\n",
        "\n",
        "    # Obtener los nombres de las clases (suponiendo que están en df_filtrados.columns)\n",
        "    labels_names = list(df_filtrado['diagnosis'].unique())\n",
        "    # Registrar el heatmap y la grilla de valores en TensorBoard\n",
        "    log_heatmap(writer, epoch, all_groundtruth, all_predictions, labels_names)\n",
        "    log_values_predicted(writer, epoch, all_groundtruth, all_predictions)\n",
        "    \n",
        "    # Carga de hiperparametros y metricas\n",
        "    execution_statistics = {\n",
        "        \"epoch\": epoch+1,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"num_epochs\": num_epochs,\n",
        "        \"Train Loss\": train_loss,\n",
        "        \"Validation Loss\": val_loss,\n",
        "        \"Train Accuracy\": train_accuracy,\n",
        "        \"Validation Accuracy\": val_accuracy\n",
        "        \n",
        "    }\n",
        "    \n",
        "    executionStatistics_list.append(execution_statistics)\n",
        "    \n",
        "    # Gráfica de loss y accuracy por cada epoca\n",
        "    writer.add_scalars(\"Loss\", {\"Train\": train_loss, \"Validation\": val_loss}, epoch)\n",
        "    writer.add_scalars(\"Accuracy\", {\"Train\": train_accuracy, \"Validation\": val_accuracy}, epoch)\n",
        "    \n",
        "    \n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} FINISHED => \"\n",
        "        f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "        f\"Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")\n",
        "    \n",
        "\n",
        "\n",
        "writer.flush()\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Guardado de los resultados del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_statistics = pd.DataFrame.from_dict(executionStatistics_list)\n",
        "df_statistics.to_excel(os.path.join(savedResultsRoute, f\"{executionModelDateTime}_results.xlsx\"), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agregado de Hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Guardado del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Guardado del modelo completo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "F8oSSsxF3tTB"
      },
      "outputs": [],
      "source": [
        "torch.save(model, os.path.join(savedModelsRoute, f\"{executionModelDateTime}_modelo_entrenado_resnet18_softAtt_ka_completo.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Guardado de los pesos del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), os.path.join(savedModelsRoute, f\"{executionModelDateTime}_modelo_entrenado_resnet18_softAtt_ka_pesos.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'MEL': 0, 'NV': 1, 'BCC': 2, 'BKL': 3, 'AK': 4}\n"
          ]
        }
      ],
      "source": [
        "# Mapeo de clases\n",
        "print(train_dataset.class_to_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prueba del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "Predicción: BKL\n"
          ]
        }
      ],
      "source": [
        "model.eval()  # Ponemos el modelo en modo de evaluación\n",
        "\n",
        "# Paso 3: Cargar la imagen y aplicar las transformaciones\n",
        "image_path = 'ka.jpg'  # Pon aquí la ruta de tu imagen\n",
        "image = Image.open(image_path)  # Abrir la imagen\n",
        "image_tensor = val_transform(image)  # Aplicar las transformaciones\n",
        "\n",
        "image_tensor = image_tensor.unsqueeze(0)  # Convertirlo a un batch de tamaño 1\n",
        "\n",
        "# Paso 5: Mover la imagen al dispositivo (GPU o CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "image_tensor = image_tensor.to(device)\n",
        "model = model.to(device)\n",
        "\n",
        "# Paso 6: Realizar la predicción\n",
        "with torch.no_grad():  # No necesitamos gradientes para la inferencia\n",
        "    output = model(image_tensor)\n",
        "\n",
        "# Paso 7: Convertir las predicciones en probabilidades con softmax\n",
        "probabilities = torch.nn.functional.softmax(output, dim=1)  # Usamos dim=1 porque tenemos un batch\n",
        "\n",
        "# Paso 8: Obtener la clase con la mayor probabilidad\n",
        "_, predicted_class = torch.max(probabilities, dim=1)\n",
        "\n",
        "# Paso 9: Interpretar la clase predicha\n",
        "# Usamos el mapeo que ya tienes de clases (el 'class_to_idx' que ya definiste en tu dataset)\n",
        "predicted_idx = predicted_class.item()  # Obtenemos el índice de la clase predicha\n",
        "print(predicted_idx)\n",
        "# Aquí usamos el mapeo de clases que creamos antes para convertir el índice a una clase legible\n",
        "predicted_class_name = [key for key, value in train_dataset.class_to_idx.items() if value == predicted_idx][0]\n",
        "\n",
        "# Mostrar la clase predicha\n",
        "print(f\"Predicción: {predicted_class_name}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
