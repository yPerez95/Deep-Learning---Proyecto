{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo8RnaiRug7e"
      },
      "source": [
        "# **Modelo CNN Simple - ResNet18 + Dropout + Soft Attention Espacial** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kTmTkZCHywa2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pre-entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y-4fhcf_yxMv"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Redimensionar a un tama帽o fijo (ej. 128x128)\n",
        "    transforms.ToTensor(),  # Convertir la imagen a un tensor de PyTorch\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalizaci贸n (media y desviaci贸n est谩ndar de im谩genes ImageNet)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definici贸n del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u-v6MsjVzY6k"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (str): Ruta al archivo CSV con las im谩genes y sus etiquetas.\n",
        "            img_dir (str): Ruta al directorio que contiene las im谩genes.\n",
        "            transform (callable, optional): Transformaciones que se aplican a las im谩genes.\n",
        "        \"\"\"\n",
        "        self.img_labels = pd.read_csv(csv_file)  # Leer el archivo CSV con las etiquetas\n",
        "        self.img_dir = img_dir  # Ruta donde est谩n las im谩genes\n",
        "        self.transform = transform  # Transformaciones a aplicar\n",
        "\n",
        "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.img_labels['diagnosis'].unique())}\n",
        "    def __len__(self):\n",
        "        \"\"\"Retorna el n煤mero total de im谩genes en el dataset\"\"\"\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Obtiene una imagen y su etiqueta\"\"\"\n",
        "        img_name = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])  # Nombre de la imagen\n",
        "        image = Image.open(img_name)  # Abrir la imagen\n",
        "        label = self.class_to_idx[self.img_labels.iloc[idx, 3]] # Etiqueta asociada\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)  # Aplicar transformaciones si es necesario\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Generaci贸n del dataset de entrenamiento y validaci贸n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Leer el CSV\n",
        "csvRoute=\"./content/GPTeam-DeepLearning/Dataset/bcn_20k_train.csv\"\n",
        "imagesFolderRoute = \"./content/GPTeam-DeepLearning/Dataset/bcn_20k_train/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(csvRoute)\n",
        "#Definir las clases que deseas excluir por su nombre\n",
        "clases_a_excluir = ['SCC', 'DF', 'VASC']  # Sustituye estos nombres por las clases que quieres excluir\n",
        "\n",
        "# Filtrar el DataFrame para excluir las clases especificadas\n",
        "df_filtrado = df[~df['diagnosis'].isin(clases_a_excluir)]\n",
        "\n",
        "filteredCsvRoute = \"./content/GPTeam-DeepLearning/Dataset/bcn_20k_train_filtrado.csv\"\n",
        "df_filtrado.to_csv(filteredCsvRoute, index=False)\n",
        "\n",
        "# Dividir el dataset en entrenamiento (80%) y validaci贸n (20%)\n",
        "train_df, val_df = train_test_split(df_filtrado, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear el dataset de entrenamiento y validaci贸n\n",
        "train_dataset = CustomDataset(csv_file=filteredCsvRoute, img_dir=imagesFolderRoute, transform=transform)\n",
        "val_dataset = CustomDataset(csv_file=filteredCsvRoute, img_dir=imagesFolderRoute, transform=transform)\n",
        "\n",
        "# Actualizar los datasets con los subconjuntos correspondientes\n",
        "train_dataset.img_labels = train_df\n",
        "val_dataset.img_labels = val_df\n",
        "\n",
        "# Crear los DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Guardado de los datasets divididos inicialmente**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.to_json('data_train_resnet18_softAtt.json', orient='records', lines=True)\n",
        "val_df.to_json('data_val_resnet18_softAtt.json', orient='records', lines=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Definici贸n del Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mecanismo de Soft-Attention Espacial\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv_attention = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 1, kernel_size=1),  # Mapa de atenci贸n 1x1\n",
        "            nn.Softmax(dim=2)                           # Normalizaci贸n espacial\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x: (batch, 512, H, W) [Ej: (batch, 512, 7, 7)]\n",
        "        # Generar mapa de atenci贸n (batch, 1, H, W)\n",
        "        attn_weights = self.conv_attention(x)\n",
        "        # Aplicar atenci贸n: caracter铆sticas * pesos\n",
        "        attended_features = x * attn_weights  # Broadcasting autom谩tico\n",
        "        \n",
        "        return attended_features\n",
        "\n",
        "\n",
        "# Modelo ResNet18 con Dropout + Soft-Attention\n",
        "class ResNet18WithAttention(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet18WithAttention, self).__init__()\n",
        "        # 1. Cargar ResNet18 preentrenado\n",
        "        self.resnet18 = models.resnet18(pretrained=True)\n",
        "        \n",
        "        # 2. Congelar capas convolucionales\n",
        "        for param in self.resnet18.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "        # 3. A帽adir mecanismo de atenci贸n espacial\n",
        "        self.attention = SpatialAttention(in_channels=512)  # ResNet18 tiene 512 canales al final\n",
        "        \n",
        "        # 4. Modificar capas FC con Dropout\n",
        "        self.resnet18.fc = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extraer caracter铆sticas hasta la 煤ltima capa convolucional\n",
        "        x = self.resnet18.conv1(x)\n",
        "        x = self.resnet18.bn1(x)\n",
        "        x = self.resnet18.relu(x)\n",
        "        x = self.resnet18.maxpool(x)\n",
        "        x = self.resnet18.layer1(x)\n",
        "        x = self.resnet18.layer2(x)\n",
        "        x = self.resnet18.layer3(x)\n",
        "        x = self.resnet18.layer4(x)  # Salida: (batch, 512, 7, 7)\n",
        "        \n",
        "        # Aplicar atenci贸n espacial\n",
        "        x = self.attention(x)  # (batch, 512, 7, 7) con pesos aprendidos\n",
        "        \n",
        "        # Global Average Pooling y clasificaci贸n\n",
        "        x = self.resnet18.avgpool(x)  # (batch, 512, 1, 1)\n",
        "        x = torch.flatten(x, 1)       # (batch, 512)\n",
        "        x = self.resnet18.fc(x)       # (batch, num_classes)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Entrenamiento y validaci贸n del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  **Funci贸n para graficar Loss y Accuracy**\n",
        "def plot_metrics(train_values, val_values, ylabel, title, legend_train, legend_val, num_epochs):\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, num_epochs + 1), train_values, label=legend_train, marker='o')\n",
        "    plt.plot(range(1, num_epochs + 1), val_values, label=legend_val, marker='s')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    return plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 => Train Loss: 1.1724, Val Loss: 1.0755, Train Acc: 54.26%, Val Acc: 54.92%\n",
            "Epoch 2/10 => Train Loss: 1.0309, Val Loss: 1.0277, Train Acc: 60.10%, Val Acc: 60.01%\n",
            "Epoch 3/10 => Train Loss: 0.9880, Val Loss: 1.0434, Train Acc: 62.02%, Val Acc: 61.40%\n",
            "Epoch 4/10 => Train Loss: 0.9607, Val Loss: 1.0301, Train Acc: 62.97%, Val Acc: 62.36%\n",
            "Epoch 5/10 => Train Loss: 0.9336, Val Loss: 0.9919, Train Acc: 63.95%, Val Acc: 63.39%\n",
            "Epoch 6/10 => Train Loss: 0.9097, Val Loss: 0.9980, Train Acc: 65.34%, Val Acc: 64.45%\n",
            "Epoch 7/10 => Train Loss: 0.8928, Val Loss: 0.9749, Train Acc: 65.48%, Val Acc: 64.71%\n",
            "Epoch 8/10 => Train Loss: 0.8735, Val Loss: 0.9765, Train Acc: 65.82%, Val Acc: 64.92%\n",
            "Epoch 9/10 => Train Loss: 0.8618, Val Loss: 0.9735, Train Acc: 67.18%, Val Acc: 66.23%\n",
            "Epoch 10/10 => Train Loss: 0.8309, Val Loss: 0.9764, Train Acc: 68.00%, Val Acc: 66.72%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "writer = SummaryWriter()\n",
        "# Definici贸n de la cantidad de clases, la funci贸n de perdida, el optimizador y el learning rate est谩tico\n",
        "modelAt = ResNet18WithAttention(num_classes=5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modelAt.parameters(), lr=0.001)\n",
        "\n",
        "# Entrenar el modelo\n",
        "num_epochs = 10\n",
        "\n",
        "model = modelAt.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Modo entrenamiento\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "\n",
        "    # Entrenamiento\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Estad铆sticas de la p茅rdida\n",
        "        running_loss += loss.item()\n",
        "        # Precisi贸n\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_preds += (predicted == labels).sum().item()\n",
        "        total_preds += labels.size(0)\n",
        "\n",
        "    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_dataloader)}, Accuracy: {100 * correct_preds / total_preds}%\")\n",
        "    train_loss = running_loss / len(train_dataloader)\n",
        "    train_accuracy = 100 * correct_preds / total_preds\n",
        "\n",
        "    # Validaci贸n\n",
        "    model.eval()  # Modo evaluaci贸n\n",
        "    running_val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():  # No calcular gradientes durante la validaci贸n\n",
        "        for inputs, labels in val_dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_val_loss += loss.item()\n",
        "            \n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_preds += (predicted == labels).sum().item()\n",
        "            total_preds += labels.size(0)\n",
        "\n",
        "    val_loss = running_val_loss/len(val_dataloader)\n",
        "    val_accuracy = 100 * correct_preds / total_preds\n",
        "    \n",
        "    \n",
        "    # Agregar valores a TensorBoard\n",
        "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
        "    writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\n",
        "    writer.add_scalar(\"Accuracy/Train\", train_accuracy, epoch)\n",
        "    writer.add_scalar(\"Accuracy/Validation\", val_accuracy, epoch)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} => \"\n",
        "        f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "        f\"Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")\n",
        "    \n",
        "    # --- Registra los valores progresivamente ---\n",
        "    # Con add_scalars se crean 2 gr谩ficas:\n",
        "    # 1. \"Loss\" con las curvas \"Train\" y \"Validation\"\n",
        "    writer.add_scalars(\"Loss\", {\"Train\": train_loss, \"Validation\": val_loss}, epoch)\n",
        "    # 2. \"Accuracy\" con las curvas \"Train\" y \"Validation\"\n",
        "    writer.add_scalars(\"Accuracy\", {\"Train\": train_accuracy, \"Validation\": val_accuracy}, epoch)\n",
        "\n",
        "writer.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ejecutar desde cmd lo siguiente para ver desde la p谩gina tensorboard: tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Guardado del modelo completo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "F8oSSsxF3tTB"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'modelo_entrenado_resnet18_softAtt_ka_completo_70_5_clases.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Guardado de los pesos del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'modelo_entrenado_resnet18_softAtt_ka_pesos_70_5_clases.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Evaluaci贸n en datos reales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'MEL': 0, 'NV': 1, 'BCC': 2, 'BKL': 3, 'AK': 4}\n"
          ]
        }
      ],
      "source": [
        "# Mapeo de clases\n",
        "print(train_dataset.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "Predicci贸n: AK\n"
          ]
        }
      ],
      "source": [
        "model.eval()  # Ponemos el modelo en modo de evaluaci贸n\n",
        "\n",
        "# Paso 3: Cargar la imagen y aplicar las transformaciones\n",
        "image_path = 'ka.jpg'  # Pon aqu铆 la ruta de tu imagen\n",
        "image = Image.open(image_path)  # Abrir la imagen\n",
        "image_tensor = transform(image)  # Aplicar las transformaciones\n",
        "\n",
        "image_tensor = image_tensor.unsqueeze(0)  # Convertirlo a un batch de tama帽o 1\n",
        "\n",
        "# Paso 5: Mover la imagen al dispositivo (GPU o CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "image_tensor = image_tensor.to(device)\n",
        "model = model.to(device)\n",
        "\n",
        "# Paso 6: Realizar la predicci贸n\n",
        "with torch.no_grad():  # No necesitamos gradientes para la inferencia\n",
        "    output = model(image_tensor)\n",
        "\n",
        "# Paso 7: Convertir las predicciones en probabilidades con softmax\n",
        "probabilities = torch.nn.functional.softmax(output, dim=1)  # Usamos dim=1 porque tenemos un batch\n",
        "\n",
        "# Paso 8: Obtener la clase con la mayor probabilidad\n",
        "_, predicted_class = torch.max(probabilities, dim=1)\n",
        "\n",
        "# Paso 9: Interpretar la clase predicha\n",
        "# Usamos el mapeo que ya tienes de clases (el 'class_to_idx' que ya definiste en tu dataset)\n",
        "predicted_idx = predicted_class.item()  # Obtenemos el 铆ndice de la clase predicha\n",
        "print(predicted_idx)\n",
        "# Aqu铆 usamos el mapeo de clases que creamos antes para convertir el 铆ndice a una clase legible\n",
        "predicted_class_name = [key for key, value in train_dataset.class_to_idx.items() if value == predicted_idx][0]\n",
        "\n",
        "# Mostrar la clase predicha\n",
        "print(f\"Predicci贸n: {predicted_class_name}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
