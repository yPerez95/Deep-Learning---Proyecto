{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelo CNN Simple - ResNet18 + Dropout + Soft Attention Espacial** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchsummary import summary\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de transformación de los datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion de parámetros para la modificación de imágenes\n",
    "crop_size = (64, 64)\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "rotation_grade = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(rotation_grade),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Ruta al archivo CSV con las imágenes y sus etiquetas.\n",
    "            img_dir (str): Ruta al directorio que contiene las imágenes.\n",
    "            transform (callable, optional): Transformaciones que se aplican a las imágenes.\n",
    "        \"\"\"\n",
    "        self.img_labels = pd.read_csv(csv_file)  # Leer el archivo CSV con las etiquetas\n",
    "        self.img_dir = img_dir  # Ruta donde están las imágenes\n",
    "        self.transform = transform  # Transformaciones a aplicar\n",
    "\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.img_labels['diagnosis'].unique())}\n",
    "    def __len__(self):\n",
    "        \"\"\"Retorna el número total de imágenes en el dataset\"\"\"\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Obtiene una imagen y su etiqueta\"\"\"\n",
    "        img_name = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])  # Nombre de la imagen\n",
    "        image = Image.open(img_name)  # Abrir la imagen\n",
    "        label = self.class_to_idx[self.img_labels.iloc[idx, 3]] # Etiqueta asociada\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Aplicar transformaciones si es necesario\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rutas de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el CSV\n",
    "csvRoute=\"./content/GPTeam-DeepLearning/Dataset/bcn_20k_train.csv\"\n",
    "imagesFolderRoute = \"./content/GPTeam-DeepLearning/Dataset/bcn_20k_train/\"\n",
    "trainDataJsonRoute = \"./content/GPTeam-DeepLearning/Dataset/data_train_resnet18_softAtt.json\"\n",
    "validationDataJsonRoute= \"./content/GPTeam-DeepLearning/Dataset/data_val_resnet18_softAtt.json\"\n",
    "filteredCsvRoute = \"./content/GPTeam-DeepLearning/Dataset/bcn_20k_train_filtrado.csv\"\n",
    "logsRoute = \"./runs\"\n",
    "savedParametersRoute = \"./saved_models_parameters/Parameters\"\n",
    "savedModelsRoute = \"./saved_models_parameters/Models\"\n",
    "savedResultsRoute = \"./results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación del dataset de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Carga del dataframe***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bcn_filename</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>capture_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCN_0000000001.jpg</td>\n",
       "      <td>55.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0003884</td>\n",
       "      <td>2012-05-16</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCN_0000000003.jpg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0000019</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCN_0000000004.jpg</td>\n",
       "      <td>85.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>SCC</td>\n",
       "      <td>BCN_0003499</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCN_0000000006.jpg</td>\n",
       "      <td>60.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>NV</td>\n",
       "      <td>BCN_0003316</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCN_0000000010.jpg</td>\n",
       "      <td>30.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCN_0004874</td>\n",
       "      <td>2014-02-18</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bcn_filename  age_approx anatom_site_general diagnosis    lesion_id  \\\n",
       "0  BCN_0000000001.jpg        55.0      anterior torso       MEL  BCN_0003884   \n",
       "1  BCN_0000000003.jpg        50.0      anterior torso       MEL  BCN_0000019   \n",
       "2  BCN_0000000004.jpg        85.0           head/neck       SCC  BCN_0003499   \n",
       "3  BCN_0000000006.jpg        60.0      anterior torso        NV  BCN_0003316   \n",
       "4  BCN_0000000010.jpg        30.0      anterior torso       BCC  BCN_0004874   \n",
       "\n",
       "  capture_date     sex  split  \n",
       "0   2012-05-16    male  train  \n",
       "1   2015-07-09  female  train  \n",
       "2   2015-11-23    male  train  \n",
       "3   2015-06-16    male  train  \n",
       "4   2014-02-18  female  train  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csvRoute)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exclusión de clases menos representativas***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MEL', 'NV', 'BCC', 'BKL', 'AK'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = df.copy()\n",
    "#Definir las clases que deseas excluir por su nombre\n",
    "clases_a_excluir = ['SCC', 'DF', 'VASC']  # Sustituye estos nombres por las clases que quieres excluir\n",
    "\n",
    "# Filtrar el DataFrame para excluir las clases especificadas\n",
    "df_filtrado = df[~df['diagnosis'].isin(clases_a_excluir)]\n",
    "df_filtrado.to_csv(filteredCsvRoute, index=False)\n",
    "df = df_filtrado.copy()\n",
    "df_filtrado['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Busqueda de spliteo adecuado (sin lesson_id iguales para dataset de entrenamiento y validación)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state encontrado: 25\n"
     ]
    }
   ],
   "source": [
    "# Obtener los valores únicos de lesion_id\n",
    "unique_lesions = df['lesion_id'].unique()\n",
    "\n",
    "# Búsqueda del mejor split\n",
    "best_train, best_test = None, None\n",
    "target_ratio = 0.8 * len(df)\n",
    "\n",
    "for seed in range(1000):  # Exploramos diferentes random_state\n",
    "    train_ids, test_ids = train_test_split(unique_lesions, test_size=0.2, random_state=seed)\n",
    "\n",
    "    x_train = df[df['lesion_id'].isin(train_ids)]\n",
    "    x_test = df[df['lesion_id'].isin(test_ids)]\n",
    "\n",
    "    # Verificar que la cantidad de filas sea la correcta Y que los lesion_id no se repitan\n",
    "    if abs(len(x_train) - target_ratio) < 1 and set(x_train['lesion_id']).isdisjoint(set(x_test['lesion_id'])):\n",
    "        best_train, best_test = x_train, x_test\n",
    "        print(f\"Random state encontrado: {seed}\")\n",
    "        break\n",
    "\n",
    "# Si no se encontró un split válido, lanzar error\n",
    "if best_train is None or best_test is None:\n",
    "    raise ValueError(\"No se encontró un split válido después de 1000 intentos\")\n",
    "\n",
    "# Asignar los mejores valores encontrados\n",
    "train_df, val_df = best_train, best_test\n",
    "\n",
    "assert set(train_df['lesion_id']).isdisjoint(set(val_df['lesion_id'])), \"Error: Hay lesion_id repetidos entre train_df y val_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICACION ADICIONAL DE NO REPETICION DE LESSIONID EN AMBOS DATASETS\n",
    "for idtrain in train_df['lesion_id'].unique():\n",
    "    for idval in val_df['lesion_id'].unique():\n",
    "        if idtrain.strip() == idval.strip():\n",
    "            print(\"Coincidence found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Carga de las imágenes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el dataset de entrenamiento y validación\n",
    "train_dataset = CustomDataset(csv_file=filteredCsvRoute, img_dir=imagesFolderRoute, transform=transform)\n",
    "val_dataset = CustomDataset(csv_file=filteredCsvRoute, img_dir=imagesFolderRoute, transform=transform)\n",
    "\n",
    "# Actualizar los datasets con los subconjuntos correspondientes\n",
    "train_dataset.img_labels = train_df\n",
    "val_dataset.img_labels = val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de imagenes faltantes: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la carga de todos los arhivos\n",
    "archivos_en_directorio = []\n",
    "# Recorrer todos los archivos en el directorio\n",
    "for archivo in os.listdir(imagesFolderRoute):\n",
    "    if os.path.isfile(os.path.join(imagesFolderRoute, archivo)):\n",
    "        archivos_en_directorio.append(archivo)\n",
    "\n",
    "# La columna del DataFrame con los nombres de los archivos\n",
    "column_files = df['bcn_filename']\n",
    "# Convertir las listas a conjuntos para realizar la diferencia\n",
    "set_column_files = set(column_files)\n",
    "set_archivos_en_drive = set(archivos_en_directorio)\n",
    "valores_faltantes = set_column_files - set_archivos_en_drive\n",
    "\n",
    "print(f\"Cantidad de imagenes faltantes: {len(valores_faltantes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Guardado de los datasets divididos inicialmente**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guardado de data de dataframes de entrenamiento y validación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_json(trainDataJsonRoute, orient='records', lines=True)\n",
    "val_df.to_json(validationDataJsonRoute, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definición del Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Módulo transformer para procesar secuencias, usando batch_first.\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_length, d_model=256, nhead=8, num_layers=2, dropout=0.5):\n",
    "        super(TransformerModule, self).__init__()\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(seq_length, d_model))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_length, d_model)\n",
    "        x = x + self.pos_embedding.unsqueeze(0)\n",
    "        x = self.transformer_encoder(x)  # Ahora sin necesidad de transponer\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class CNNTransformerClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo híbrido que integra una CNN de 4 capas (divididas en 2 bloques con pooling)\n",
    "    con un módulo Transformer. La salida final es una clasificación en 5 clases.\n",
    "    Se aplican BatchNorm, Dropout y se inicializan pesos con Kaiming.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=5, dropout=0.5):\n",
    "        super(CNNTransformerClassifier, self).__init__()\n",
    "        # Bloque 1\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 64x64 -> 32x32\n",
    "\n",
    "        # Bloque 2\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4   = nn.BatchNorm2d(256)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # 32x32 -> 16x16\n",
    "\n",
    "        # Datos para el transformer\n",
    "        self.feature_map_size = 16  # luego de pool2 (16x16)\n",
    "        self.seq_length = self.feature_map_size * self.feature_map_size  # 256 tokens\n",
    "        self.d_model = 256  # dimensión de cada token\n",
    "\n",
    "        # Módulo Transformer\n",
    "        self.transformer = TransformerModule(seq_length=self.seq_length, d_model=self.d_model, nhead=8, num_layers=2, dropout=dropout)\n",
    "\n",
    "        # Capa final para clasificación\n",
    "        self.fc = nn.Linear(self.d_model, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bloque 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        # Bloque 2\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)  # x: (B, 256, 16, 16)\n",
    "\n",
    "        B, C, H, W = x.size()\n",
    "        # Reorganizar para formar secuencia: (B, tokens, d_model)\n",
    "        x = x.view(B, C, -1)    # (B, 256, 256)\n",
    "        x = x.transpose(1, 2)   # (B, 256, 256)\n",
    "\n",
    "        # Procesar con el Transformer\n",
    "        x = self.transformer(x)  # (B, d_model)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización de la ejecución del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar desde cmd lo siguiente para ver desde el navegador el menú de tensorboard: tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 22044), started 1 day, 20:23:56 ago. (Use '!kill 22044' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e7e0947de604c9c9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e7e0947de604c9c9\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Entrenamiento y validación del modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definición de gráficas adicionales a emplear**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para registrar el heatmap (matriz de confusión)\n",
    "def log_heatmap(writer, epoch, ground_truth, predictions, labels):\n",
    "    # Calcula la matriz de confusión usando el orden de las etiquetas\n",
    "    cm = confusion_matrix(ground_truth, predictions, labels=range(len(labels)))\n",
    "    \n",
    "    # Crear la figura\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=labels, yticklabels=labels, ax=ax)\n",
    "    ax.set_xlabel(\"Predicción\")\n",
    "    ax.set_ylabel(\"Groundtruth\")\n",
    "    ax.set_title(\"Matriz de Confusión\")\n",
    "    \n",
    "    # Registrar la figura en TensorBoard\n",
    "    writer.add_figure(\"Heatmap\", fig, global_step=epoch)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Función para registrar la grilla 2x2 de TP, FP, TN, FN (para clasificación binaria)\n",
    "def log_values_predicted(writer, epoch, ground_truth, predictions):\n",
    "    # Calcular la matriz de confusión\n",
    "    cm = confusion_matrix(ground_truth, predictions, labels=[0, 1])\n",
    "    \n",
    "    # Crear anotaciones combinando etiqueta y valor\n",
    "    annot = np.array([\n",
    "        [f\"TN\\n{cm[0,0]}\", f\"FP\\n{cm[0,1]}\"],\n",
    "        [f\"FN\\n{cm[1,0]}\", f\"TP\\n{cm[1,1]}\"]\n",
    "    ])\n",
    "    \n",
    "    # Crear el heatmap\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=annot, fmt=\"\", cmap=\"Blues\",\n",
    "                xticklabels=[\"False\", \"True\"],\n",
    "                yticklabels=[\"False\", \"True\"],\n",
    "                cbar=True, ax=ax)\n",
    "    ax.set_xlabel(\"Eje Predicho (False/True)\")\n",
    "    ax.set_ylabel(\"Eje Verdadero (False/True)\")\n",
    "    ax.set_title(\"Predicción de valores\")\n",
    "    \n",
    "    # Registrar la figura en TensorBoard\n",
    "    writer.add_figure(\"Predicción de valores\", fig, global_step=epoch)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seteo del dispositivo a usar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo utilizado: cuda (NVIDIA GeForce RTX 2060)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(F\"Dispositivo utilizado: {device} ({torch.cuda.get_device_name()})\")\n",
    "else:\n",
    "    print(F\"Dispositivo utilizado: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Especificación de parámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_classes = 5\n",
    "num_epochs = 3\n",
    "batch_size = 64\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training: 100%|██████████| 147/147 [04:15<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 FINISHED => Train Loss: 1.4641, Val Loss: 1.5839, Train Acc: 45.65%, Val Acc: 46.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Training: 100%|██████████| 147/147 [03:44<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 FINISHED => Train Loss: 1.2011, Val Loss: 1.1752, Train Acc: 54.68%, Val Acc: 55.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Training: 100%|██████████| 147/147 [03:39<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 FINISHED => Train Loss: 1.1573, Val Loss: 1.4369, Train Acc: 56.58%, Val Acc: 56.10%\n"
     ]
    }
   ],
   "source": [
    "# Inicialización de tensorboard\n",
    "executionModelDateTime = datetime.now().strftime(\"Ejecucion %d-%m-%Y %H-%M\")\n",
    "writer = SummaryWriter(log_dir=os.path.join(logsRoute,executionModelDateTime))\n",
    "\n",
    "# Crear los DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Definición de la cantidad de clases, la función de perdida, el optimizador y el learning rate estático\n",
    "modelAt = CNNTransformerClassifier(num_classes=num_classes, dropout=dropout)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(modelAt.parameters(), lr=learning_rate)\n",
    "model = modelAt.to(device)\n",
    "executionStatistics_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Modo entrenamiento\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    # Entrenamiento\n",
    "    for inputs, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", leave=True):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Estadísticas de la pérdida\n",
    "        running_loss += loss.item()\n",
    "        # Precisión\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "        total_preds += labels.size(0)\n",
    "\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_dataloader)}, Accuracy: {100 * correct_preds / total_preds}%\")\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    train_accuracy = 100 * correct_preds / total_preds\n",
    "\n",
    "    # Validación\n",
    "    model.eval()  # Modo evaluación\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_groundtruth = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # No calcular gradientes durante la validación\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "            all_groundtruth.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    val_loss = running_val_loss/len(val_dataloader)\n",
    "    val_accuracy = 100 * correct_preds / total_preds\n",
    "    \n",
    "    \n",
    "    # Agregar valores a TensorBoard\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Train\", train_accuracy, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Validation\", val_accuracy, epoch)\n",
    "\n",
    "    # Obtener los nombres de las clases (suponiendo que están en df_filtrados.columns)\n",
    "    labels_names = list(df_filtrado['diagnosis'].unique())\n",
    "    # Registrar el heatmap y la grilla de valores en TensorBoard\n",
    "    log_heatmap(writer, epoch, all_groundtruth, all_predictions, labels_names)\n",
    "    log_values_predicted(writer, epoch, all_groundtruth, all_predictions)\n",
    "    \n",
    "    # Carga de hiperparametros y metricas\n",
    "    execution_statistics = {\n",
    "        \"epoch\": epoch+1,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"Train Loss\": train_loss,\n",
    "        \"Validation Loss\": val_loss,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Validation Accuracy\": val_accuracy\n",
    "        \n",
    "    }\n",
    "    \n",
    "    executionStatistics_list.append(execution_statistics)\n",
    "    \n",
    "    # Gráfica de loss y accuracy por cada epoca\n",
    "    writer.add_scalars(\"Loss\", {\"Train\": train_loss, \"Validation\": val_loss}, epoch)\n",
    "    writer.add_scalars(\"Accuracy\", {\"Train\": train_accuracy, \"Validation\": val_accuracy}, epoch)\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} FINISHED => \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "        f\"Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")\n",
    "    \n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de arquitectura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelAt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torchsummary\\torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[16], line 86\u001b[0m, in \u001b[0;36mCNNTransformerClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)   \u001b[38;5;66;03m# (B, 256, 256)\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Procesar con el Transformer\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, d_model)\u001b[39;00m\n\u001b[0;32m     87\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m     88\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1787\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1793\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1794\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1795\u001b[0m     ):\n\u001b[0;32m   1796\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m, in \u001b[0;36mTransformerModule.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# x: (B, seq_length, d_model)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ahora sin necesidad de transponer\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1787\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1793\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1794\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1795\u001b[0m     ):\n\u001b[0;32m   1796\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:511\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    508\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 511\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    519\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1787\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1793\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1794\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1795\u001b[0m     ):\n\u001b[0;32m   1796\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:904\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    900\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    902\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[0;32m    903\u001b[0m         x\n\u001b[1;32m--> 904\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m     )\n\u001b[0;32m    906\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:918\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[0;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    913\u001b[0m     x: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    916\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    917\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 918\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1803\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1801\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1803\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1806\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torchsummary\\torchsummary.py:22\u001b[0m, in \u001b[0;36msummary.<locals>.register_hook.<locals>.hook\u001b[1;34m(module, input, output)\u001b[0m\n\u001b[0;32m     20\u001b[0m summary[m_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m---> 22\u001b[0m     summary[m_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     summary[m_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32md:\\PUCP\\Cursos electivos\\Deep Learning\\Proyecto General\\Proyecto\\Deep-Learning---Proyecto\\venv\\Lib\\site-packages\\torchsummary\\torchsummary.py:23\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m summary[m_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m     22\u001b[0m     summary[m_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 23\u001b[0m         [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m())[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output\n\u001b[0;32m     24\u001b[0m     ]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     summary[m_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "summary(modelAt, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado de los resultados del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statistics = pd.DataFrame.from_dict(executionStatistics_list)\n",
    "df_statistics.to_excel(os.path.join(savedResultsRoute, f\"{executionModelDateTime}_results.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregado de Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guardado del modelo completo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, os.path.join(savedModelsRoute, f\"{executionModelDateTime}_modelo_entrenado_cnn_transformers_ka_completo.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guardado de los pesos del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(savedModelsRoute, f\"{executionModelDateTime}_modelo_entrenado_cnn_transformers_ka_pesos.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MEL': 0, 'NV': 1, 'BCC': 2, 'BKL': 3, 'AK': 4}\n"
     ]
    }
   ],
   "source": [
    "# Mapeo de clases\n",
    "print(train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Predicción: BCC\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Ponemos el modelo en modo de evaluación\n",
    "\n",
    "# Paso 3: Cargar la imagen y aplicar las transformaciones\n",
    "image_path = 'ka.jpg'  # Pon aquí la ruta de tu imagen\n",
    "image = Image.open(image_path)  # Abrir la imagen\n",
    "image_tensor = transform(image)  # Aplicar las transformaciones\n",
    "\n",
    "image_tensor = image_tensor.unsqueeze(0)  # Convertirlo a un batch de tamaño 1\n",
    "\n",
    "# Paso 5: Mover la imagen al dispositivo (GPU o CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "image_tensor = image_tensor.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Paso 6: Realizar la predicción\n",
    "with torch.no_grad():  # No necesitamos gradientes para la inferencia\n",
    "    output = model(image_tensor)\n",
    "\n",
    "# Paso 7: Convertir las predicciones en probabilidades con softmax\n",
    "probabilities = torch.nn.functional.softmax(output, dim=1)  # Usamos dim=1 porque tenemos un batch\n",
    "\n",
    "# Paso 8: Obtener la clase con la mayor probabilidad\n",
    "_, predicted_class = torch.max(probabilities, dim=1)\n",
    "\n",
    "# Paso 9: Interpretar la clase predicha\n",
    "# Usamos el mapeo que ya tienes de clases (el 'class_to_idx' que ya definiste en tu dataset)\n",
    "predicted_idx = predicted_class.item()  # Obtenemos el índice de la clase predicha\n",
    "print(predicted_idx)\n",
    "# Aquí usamos el mapeo de clases que creamos antes para convertir el índice a una clase legible\n",
    "predicted_class_name = [key for key, value in train_dataset.class_to_idx.items() if value == predicted_idx][0]\n",
    "\n",
    "# Mostrar la clase predicha\n",
    "print(f\"Predicción: {predicted_class_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
